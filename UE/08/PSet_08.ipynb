{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02281065, 0.44444444, 0.        , 0.26035503, 0.29752066,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "breast_cancer = load_breast_cancer ()\n",
    "X, y = breast_cancer.data , breast_cancer.target\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, test_size =0.2,\n",
    "random_state =42)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"gini\",\n",
    "                                    max_depth=3,\n",
    "                                    random_state =42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# visualize the model with\n",
    "dot_data = tree.export_graphviz(clf , out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"DTC_breastcancer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1d - At what max depth do we have pure leaves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At max depth 7 there are only pure leaves\n"
     ]
    }
   ],
   "source": [
    "try_tree = tree.DecisionTreeClassifier(criterion=\"gini\",\n",
    "                                    max_depth=1,\n",
    "                                    random_state=42)\n",
    "try_tree.fit(X_train, y_train)\n",
    "\n",
    "while True:\n",
    "    # Update is_leaf mask after each fit\n",
    "    is_leaf = (try_tree.tree_.children_left == -1) & (try_tree.tree_.children_right == -1)\n",
    "    \n",
    "    # Check if all leaves are pure\n",
    "    if try_tree.tree_.impurity[is_leaf].sum() == 0:\n",
    "        break\n",
    "        \n",
    "    try_tree.max_depth += 1\n",
    "    try_tree.fit(X_train, y_train)\n",
    "\n",
    "print(f\"At max depth {try_tree.max_depth} there are only pure leaves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1e - Compare accuracies of the two trees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of tree with depth 3: 0.9474\n",
      "Accuracy of tree with pure leaves (depth 7): 0.9474\n",
      "\n",
      "Their performance on the test set is nearly identical\n"
     ]
    }
   ],
   "source": [
    "# Compare accuracies of both models on test set\n",
    "acc_depth3 = clf.score(X_test, y_test)\n",
    "acc_pure_leaves = try_tree.score(X_test, y_test)\n",
    "\n",
    "print(f\"Accuracy of tree with depth 3: {acc_depth3:.4f}\")\n",
    "print(f\"Accuracy of tree with pure leaves (depth {try_tree.max_depth}): {acc_pure_leaves:.4f}\")\n",
    "\n",
    "if abs(acc_depth3 - acc_pure_leaves) < 0.01:\n",
    "    print(\"\\nTheir performance on the test set is nearly identical\")\n",
    "elif acc_depth3 > acc_pure_leaves + 0.05:\n",
    "    print(\"\\nThe depth 3 tree clearly performs better\")\n",
    "elif acc_pure_leaves > acc_depth3 + 0.05:\n",
    "    print(\"\\nThe deeper tree clearly performs better\") \n",
    "elif acc_depth3 > acc_pure_leaves:\n",
    "    print(\"\\nAlmost the same, but depth 3 shows slightly better generalization\")\n",
    "else:\n",
    "    print(\"\\nAlmost the same, but the deeper tree can get a few more samples right\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with importance > 5%:\n",
      "mean concave points: 75.23%\n",
      "worst concave points: 7.14%\n",
      "worst radius: 5.69%\n",
      "worst perimeter: 5.60%\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances from depth 3 tree\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = breast_cancer.feature_names\n",
    "\n",
    "# Find features with importance > 5%\n",
    "important_features = [(name, imp) for name, imp in zip(feature_names, importances) if imp > 0.05]\n",
    "\n",
    "print(\"Features with importance > 5%:\")\n",
    "for name, importance in sorted(important_features, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name}: {importance:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features with permutation importance > 5%:\n",
      "area error: 15.05%\n",
      "worst radius: 13.63%\n",
      "\n",
      "Comparing with Gini importance results:\n",
      "mean concave points:\n",
      "  Gini importance: 75.23%\n",
      "  Permutation importance: 1.05%\n",
      "worst concave points:\n",
      "  Gini importance: 7.14%\n",
      "  Permutation importance: 1.51%\n",
      "worst radius:\n",
      "  Gini importance: 5.69%\n",
      "  Permutation importance: 13.63%\n",
      "worst perimeter:\n",
      "  Gini importance: 5.60%\n",
      "  Permutation importance: 2.30%\n"
     ]
    }
   ],
   "source": [
    "# Calculate permutation importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Get permutation importance scores\n",
    "r = permutation_importance(clf, X_test, y_test,\n",
    "                         n_repeats=50,\n",
    "                         random_state=0, \n",
    "                         scoring='accuracy')\n",
    "\n",
    "# Find features with importance > 5%\n",
    "perm_important_features = [(name, imp) for name, imp in \n",
    "                          zip(feature_names, r.importances_mean) if imp > 0.05]\n",
    "\n",
    "print(\"\\nFeatures with permutation importance > 5%:\")\n",
    "for name, importance in sorted(perm_important_features, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name}: {importance:.2%}\")\n",
    "\n",
    "# Compare with previous Gini importance results\n",
    "print(\"\\nComparing with Gini importance results:\")\n",
    "for name, gini_imp in sorted(important_features, key=lambda x: x[1], reverse=True):\n",
    "    perm_imp = r.importances_mean[list(feature_names).index(name)]\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Gini importance: {gini_imp:.2%}\")\n",
    "    print(f\"  Permutation importance: {perm_imp:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
